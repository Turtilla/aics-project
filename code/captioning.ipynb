{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Imports/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from xml.etree.ElementTree import ParseError\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '../data/iaprtc12/'\n",
    "annotation_dir = os.path.join(data_root_dir, 'annotations_complete_eng/')\n",
    "image_dir = os.path.join(data_root_dir, 'images/')\n",
    "\n",
    "UNKNOWN_TOKEN = '<unk>'\n",
    "START_TOKEN = '<start>'\n",
    "END_TOKEN = '<end>'\n",
    "PADDING_TOKEN = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'batch_size': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@dataclass(slots=True, kw_only=True)\n",
    "class CLEFSample:\n",
    "    # by Dominik\n",
    "    image_id: str\n",
    "    caption: str\n",
    "    caption_length: torch.CharTensor\n",
    "    image_path: str\n",
    "    encoded_caption: torch.IntTensor = None\n",
    "    image: torch.FloatTensor = None\n",
    "\n",
    "\n",
    "class CLEFDataset(Dataset):\n",
    "    # by Dominik, individual contributions by Maria marked with in-line comments or comments under specific methods\n",
    "    def __init__(\n",
    "        self, \n",
    "        annotation_directory: str, \n",
    "        image_directory: str, \n",
    "        number_images=100, \n",
    "        word_map: dict = None, \n",
    "        min_frequency=10, \n",
    "        concat_captions: bool = False  # added by Maria to allow the optional concatenation of multiple captions into one\n",
    "    ) -> None:\n",
    "        super(CLEFDataset, self).__init__()\n",
    "        captions = self._load_captions(annotation_directory, number_images, concat_captions)\n",
    "        samples = self._load_images(image_directory, captions)\n",
    "\n",
    "        if word_map == None:\n",
    "            word_map = self._create_word_map(samples, min_frequency)\n",
    "        self.word_map = word_map\n",
    "\n",
    "        self.samples = self._encode_captions(samples)\n",
    "\n",
    "    def _load_captions(self, directory: str, number_images: int, concat_captions: bool) -> list[CLEFSample]:\n",
    "        captions: list[CLEFSample] = []\n",
    "\n",
    "        file_pattern = directory + '**/*.eng'\n",
    "        for file in glob(file_pattern, recursive=True):\n",
    "            if len(captions) == number_images:\n",
    "                break\n",
    "            try:\n",
    "                root = ElementTree.parse(file).getroot()\n",
    "                description = root.find('./DESCRIPTION').text\n",
    "                # multiple captions option by Maria\n",
    "                all_captions = description.split(';')\n",
    "                if concat_captions == True:\n",
    "                    first_caption = ' and '.join(all_captions[:-1])  # if not -1, then there is a trailing 'and'\n",
    "                else:\n",
    "                    first_caption = all_captions[0]\n",
    "                    \n",
    "                tokenized_caption = nltk.word_tokenize(first_caption)\n",
    "                \n",
    "                image_path = root.find('./IMAGE').text.removeprefix('images/')\n",
    "                image_id = image_path.removesuffix('.jpg')\n",
    "                \n",
    "                # selecting only the captions that include verbs or prepositions (relation words) by Maria\n",
    "                annotated_caption = nltk.pos_tag(tokenized_caption, tagset='universal')\n",
    "\n",
    "                va_counter = 0  # for seeing if there is a verb or an adposition in the description\n",
    "                for tagged_word in annotated_caption:\n",
    "                    if tagged_word[1] == 'VERB':\n",
    "                        va_counter += 1\n",
    "                    elif tagged_word[1] == 'ADP':\n",
    "                        va_counter += 1\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                if va_counter > 0:\n",
    "                    captions.append(CLEFSample(\n",
    "                        image_id=image_id,\n",
    "                        caption=tokenized_caption,\n",
    "                        # +2 for start and end token\n",
    "                        caption_length=torch.CharTensor([len(tokenized_caption) + 2]),\n",
    "                        image_path=image_path\n",
    "                    ))\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            except ParseError:\n",
    "                continue\n",
    "        \n",
    "        print('Captions loaded!')  # added for clarity by Maria\n",
    "\n",
    "        return captions\n",
    "\n",
    "    def _load_images(self, directory: str, captions: list[CLEFSample]) -> list[CLEFSample]:\n",
    "        transform = transforms.ToTensor()\n",
    "\n",
    "        samples: list[CLEFSample] = []\n",
    "        for sample in tqdm(captions, desc='Loading images...'):  # tqdm added because Maria is impatient\n",
    "            image_path = os.path.join(directory, sample.image_path)\n",
    "\n",
    "            # TODO correct conversion?\n",
    "            # error-handling added by Maria\n",
    "            try:\n",
    "                image = Image.open(image_path).resize((256, 256)).convert('RGB')\n",
    "                sample.image = transform(image)\n",
    "                samples.append(sample)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "        print('Images loaded!')  # added for clarity by Maria\n",
    "        \n",
    "        return samples\n",
    "\n",
    "    def _create_word_map(self, samples: list[CLEFSample], min_frequency: int) -> dict:\n",
    "        word_frequency = Counter()\n",
    "        for sample in samples:\n",
    "            word_frequency.update(sample.caption)\n",
    "\n",
    "        words = [word for word in word_frequency.keys() if word_frequency[word] >= min_frequency]\n",
    "\n",
    "        word_map = {word: index for index, word in enumerate(words, start=1)}\n",
    "        word_map[UNKNOWN_TOKEN] = len(word_map) + 1\n",
    "        word_map[START_TOKEN] = len(word_map) + 1\n",
    "        word_map[END_TOKEN] = len(word_map) + 1\n",
    "        word_map[PADDING_TOKEN] = 0\n",
    "\n",
    "        return word_map\n",
    "\n",
    "    def _encode_captions(self, samples: list[CLEFSample]) -> list[CLEFSample]:\n",
    "        encoded_samples: list[CLEFSample] = []\n",
    "        for sample in samples:\n",
    "            encoding = [self.get_encoded_token(START_TOKEN), *[self.get_encoded_token(token)\n",
    "                                                               for token in sample.caption], self.get_encoded_token(END_TOKEN)]\n",
    "            sample.encoded_caption = torch.IntTensor(encoding)\n",
    "            encoded_samples.append(sample)\n",
    "        return encoded_samples\n",
    "\n",
    "    def get_encoded_token(self, token: str) -> int:\n",
    "        if token in self.word_map:\n",
    "            return self.word_map[token]\n",
    "        else:\n",
    "            return self.word_map[UNKNOWN_TOKEN]\n",
    "\n",
    "    def __getitem__(self, index: int) -> CLEFSample:\n",
    "        return self.samples[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(samples: list[CLEFSample]) -> dict:\n",
    "    # by Dominik\n",
    "    image_ids = []\n",
    "    captions = []\n",
    "    caption_lengths = []\n",
    "    encoded_captions = []\n",
    "    image_paths = []\n",
    "    images = []\n",
    "\n",
    "    for sample in samples:\n",
    "        image_ids.append(sample.image_id)\n",
    "        captions.append(sample.caption)\n",
    "        caption_lengths.append(sample.caption_length)\n",
    "        encoded_captions.append(sample.encoded_caption)\n",
    "        image_paths.append(sample.image_path)\n",
    "        images.append(sample.image)\n",
    "    \n",
    "    return {\n",
    "        'image_ids': image_ids,\n",
    "        'captions': captions,\n",
    "        'caption_lengths': caption_lengths,\n",
    "        'encoded_captions': pad_sequence(encoded_captions, batch_first=True),\n",
    "        'image_paths': image_paths,\n",
    "        'images': images\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images...: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 217.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = CLEFDataset(annotation_dir, image_dir, number_images=50, min_frequency=1, concat_captions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset by Maria\n",
    "# remove the last optional argument for random splits, this way the seed is fixed so results are reproducible\n",
    "# QUESTION: does this need to be done any prettier?\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by Dominik\n",
    "dataloader = DataLoader(\n",
    "    train_set, \n",
    "    hyperparameters['batch_size'], \n",
    "    shuffle=True, \n",
    "    collate_fn=custom_collate, \n",
    "    drop_last=True  # added by Maria since we were told it is good to do so when working with LSTMs in the Machine Learning 2 course\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tourists', 'are', 'visiting', 'an', 'old', 'people', \"'s\", 'home', 'and', 'each', 'tourist', 'is', 'leading', 'one', 'old', 'lady', ',', 'arm', 'in', 'arm', 'and', 'the', 'old', 'ladies', 'are', 'wearing', 'traditional', 'dresses', 'and', 'a', 'hat', 'and', 'the', 'room', 'is', 'decorated', 'with', 'balloons', 'and', 'there', 'is', 'a', 'picture', 'on', 'the', 'wall', 'in', 'the', 'background', ',', 'and', 'also', 'an', 'old', 'lady', 'carrying', 'a', 'green', 'balloon'], ['Close', 'up', 'picture', 'of', 'the', 'Itaipu', 'Dam', 'and', 'backwater', 'is', 'flowing', 'off', 'in', 'the', 'foreground'], ['a', 'woman', 'is', 'sitting', 'at', 'table', 'in', 'the', 'middle', 'of', 'a', 'schoolyard', 'and', 'there', 'are', 'many', 'books', 'on', 'the', 'table', 'and', 'two', 'people', 'are', 'sitting', 'next', 'to', 'her', ',', 'six', 'others', 'are', 'standing', 'about', 'ten', 'metres', 'away', 'from', 'the', 'table'], ['A', 'tourist', 'group', 'is', 'visiting', 'a', 'school', 'and', 'the', 'school', 'kids', 'are', 'sitting', 'at', 'their', 'desks', ',', 'singing', 'a', 'song', 'and', 'clapping', 'their', 'hands', ',', 'with', 'their', 'teacher', 'clapping', 'as', 'well', 'and', 'six', 'of', 'the', 'tourists', 'are', 'standing', 'behind', 'them', 'and', 'are', 'watching', 'them', ',', 'one', 'tourist', 'is', 'taking', 'a', 'photo'], ['Construction', 'site', ',', 'bare', 'brickwork', 'and', 'one', 'worker', 'is', 'standing', 'on', 'rails', ',', 'the', 'other', 'one', 'is', 'leaning', 'against', 'an', 'unfinished', 'brick', 'wall'], ['four', 'boys', ',', 'one', 'drinking', 'from', 'a', 'cup', ',', 'one', 'wearing', 'an', 'army', 'cap', 'and', 'waving', ',', 'the', 'one', 'in', 'the', 'focus', 'wearing', 'a', 'beanie', ',', 'a', 'jumper', 'and', 'smiling', 'into', 'the', 'camera', ',', 'and', 'the', 'fourth', 'wearing', 'a', 'cap', 'and', 'carrying', 'a', 'wooden', 'crate'], ['School', 'kids', 'on', 'a', 'grey', 'square', ',', 'some', 'are', 'dressed', 'in', 'dark', 'blue', ',', 'others', 'in', 'orange', 'and', 'one', 'person', 'dressed', 'in', 'orange', 'is', 'standing', 'opposite', 'the', 'line', 'up', ',', 'leading', 'the', 'group', 'and', 'two', 'light', 'blue', 'houses', 'behind', 'them', 'with', 'a', 'steep', 'hill', 'in', 'the', 'background'], ['five', 'women', 'in', 'a', 'kitchen', ',', 'two', 'of', 'them', 'are', 'preparing', 'some', 'food', 'using', 'four', 'bowls', ',', 'two', 'are', 'standing', 'behind', 'them', '(', 'and', 'one', 'next', 'to', 'them', ')', 'and', 'are', 'watching'], ['Nine', 'children', ',', 'some', 'of', 'them', 'waving', 'at', 'the', 'camera', ',', 'others', 'are', 'a', 'bit', 'shy', 'and', 'are', 'looking', 'away', 'and', 'one', 'person', 'is', 'pointing', 'to', 'the', 'camera'], ['against-the-light', 'photograph', 'of', 'a', 'beach', 'at', 'sunset', 'and', 'some', 'clouds', 'in', 'the', 'sky', 'and', 'there', 'are', 'people', 'at', 'the', 'beach', 'and', 'palm', 'trees', 'in', 'the', 'background'], ['a', 'rock', 'hole', 'in', 'the', 'ground', 'surrounded', 'by', 'sand', 'and', 'one', 'man', 'in', 'a', 'white', 'tee-shirt', ',', 'grey', 'pants', 'and', 'a', 'white', 'cap', 'is', 'holding', 'a', 'shovel', ',', 'the', 'other', 'one', 'is', 'wearing', 'black', 'pants', ',', 'a', 'white', 'jumper', 'and', 'a', 'traditional', 'hat', ',', 'is', 'walking', 'towards', 'him'], ['Four', 'locals', 'are', 'sitting', 'on', 'a', 'bench', 'in', 'a', 'canteen', 'kitchen', ',', 'leaning', 'on', 'a', 'red', 'brick', 'wall', 'and', 'the', 'three', 'women', 'are', 'wearing', 'skirts', ',', 'wests', 'and', 'hats', ',', 'one', 'of', 'them', 'is', 'holding', 'a', 'yellow', 'plastic', 'bag', 'and', 'the', 'man', 'is', 'wearing', 'trousers', ',', 'a', 'shirt', 'and', 'a', 'cap'], ['six', 'kids', 'are', 'sitting', 'around', 'a', 'table', 'and', 'playing', 'with', 'toy', 'cars', 'and', 'one', 'kid', 'is', 'standing', 'next', 'to', 'the', 'table', 'and', 'a', 'woman', 'is', 'holding', 'a', 'black', 'plastic', 'bag', 'on', 'the', 'left', 'and', 'three', 'tourists', 'in', 'the', 'background', 'are', 'talking', 'to', 'each', 'other'], ['About', '20', 'kids', 'in', 'traditional', 'clothing', 'and', 'hats', 'waiting', 'on', 'stairs', 'and', 'a', 'house', 'and', 'a', 'green', 'wall', 'with', 'gate', 'in', 'the', 'background', 'and', 'a', 'sign', 'saying', 'that', 'plants', 'ca', \"n't\", 'be', 'picked', 'up', 'on', 'the', 'right'], ['A', 'school', 'kid', 'is', 'sitting', 'at', 'a', 'desk', ',', 'smiling', 'into', 'the', 'camera', 'and', 'being', 'offered', 'a', 'red', 'apple', 'and', 'three', 'other', 'kids', 'in', 'the', 'background'], ['a', 'destroyed', 'house', 'with', 'the', 'wreckage', 'lying', 'around', 'in', 'front', 'it', 'and', 'three', 'ordinary', 'a', 'bit', 'elevated', 'houses', 'in', 'the', 'background'], ['classroom', 'with', 'most', 'of', 'the', 'pupil', 'sitting', 'at', 'theirs', 'desk', 'and', 'wearing', 'green', 'hats', 'and', 'one', 'girl', 'is', 'standing', 'at', 'her', 'desk', ',', 'another', 'one', 'is', 'walking', 'to', 'her', 'desk', ',', 'three', 'other', 'boys', 'are', 'standing', 'and', 'looking', 'at', 'a', 'picture', 'of', 'Minnie', 'Mouse', 'on', 'the', 'wall', 'and', 'shelves', 'and', 'posters', 'in', 'the', 'background'], ['volunteer', 'workers', 'help', 'with', 'the', 'construction', 'in', 'a', 'kindergarten', 'and', 'four', 'volunteers', 'are', 'squatting', 'down', 'and', 'are', 'trying', 'to', 'prise', 'the', 'ground', 'with', 'hammer', 'and', 'chisel', 'and', 'movable', 'wooden', 'walls', 'are', 'leaning', 'on', 'the', 'wall', 'in', 'the', 'background'], ['Four', 'tourists', 'are', 'sitting', 'on', 'a', 'bus', 'and', 'two', 'women', 'in', 'the', 'front', 'row', 'with', 'their', 'heads', 'turned', 'around', 'and', 'another', 'one', 'in', 'the', 'second', 'row', 'looking', 'out', 'the', 'window', 'and', 'and', 'one', 'man', 'with', 'sunglasses', 'in', 'the', 'very', 'last', 'row', ',', 'looking', 'out', 'the', 'window', 'too'], ['panorama', 'view', 'of', 'houses', 'in', 'La', 'Paz', 'and', 'red', 'roofed', 'houses', 'in', 'the', 'foreground', ',', 'with', 'a', 'hill', 'and', 'rugged', 'rocks', 'in', 'the', 'background'], ['a', 'man', 'is', 'carrying', 'a', 'heavy', 'rice', 'bag', 'and', 'a', 'car', 'on', 'the', 'left', ',', 'another', 'man', 'on', 'the', 'right', 'and', 'a', 'street', 'behind', 'them', ',', 'with', 'some', 'houses', 'on', 'a', 'hill', 'in', 'the', 'background'], ['photo', 'of', 'eleven', 'school', 'kids', 'and', 'three', 'tourists', 'behind', 'them', 'and', 'a', 'basketball', 'court', 'in', 'the', 'background', ',', 'with', 'one', 'kid', 'standing', 'below', 'the', 'basket', 'and', 'a', 'large', 'mountain', 'in', 'the', 'distant', 'background'], ['Lots', 'of', 'locals', '(', 'both', 'kids', 'and', 'adults', ')', 'in', 'front', 'of', 'a', 'blue', 'building', 'and', 'one', 'kid', 'is', 'about', 'to', 'slide', 'down', 'the', 'slide', ',', 'with', 'one', 'grown', 'up', 'waiting', 'to', 'catch', 'it', 'and', 'another', 'woman', 'is', 'carrying', 'a', 'basket', 'in', 'her', 'left', 'hand', ',', 'with', 'a', 'kid', 'holding', 'her', 'other', 'hand', 'and', 'others', 'are', 'just', 'sitting', 'around', 'or', 'are', 'standing', 'in', 'the', 'background', 'and', 'there', 'are', 'snow', 'covered', 'mountains', 'in', 'the', 'distant', 'background'], ['School', 'kids', 'are', 'posing', 'for', 'the', 'camera', 'in', 'a', 'football-like', 'setup', '-', 'nine', 'are', 'standing', 'at', 'the', 'back', ',', 'ten', 'are', 'squatting', 'at', 'the', 'front', 'and', 'each', 'of', 'them', 'are', 'having', 'a', 'fruit', 'in', 'their', 'hands', ',', 'most', 'of', 'them', 'are', 'smiling', ',', 'one', 'is', 'even', 'waving', 'at', 'the', 'camera', 'and', 'a', 'blackboard', 'in', 'the', 'background', 'and', 'one', 'kid', 'in', 'the', 'centre', 'of', 'the', 'front', 'row', 'is', 'holding', 'a', 'teddy'], ['children', 'are', 'sitting', 'at', 'their', 'desks', ',', 'together', 'with', 'a', 'tourist', 'sitting', 'in', 'the', 'last', 'row', 'and', 'three', 'children', 'are', 'standing', 'on', 'the', 'left', ',', 'looking', 'at', 'a', 'map', 'of', 'Peru', 'and', 'there', 'are', 'two', 'posters', 'on', 'the', 'wall', 'at', 'the', 'back', ',', 'and', 'there', 'is', 'a', 'bookshelf', 'with', 'a', 'lot', 'of', 'boxes', 'and', 'folders', 'on', 'the', 'left'], ['Pupils', 'are', 'sitting', 'at', 'their', 'wooden', 'desks', 'in', 'an', 'open', 'air', 'classroom', 'and', 'two', 'of', 'them', 'raising', 'their', 'hands', ',', 'others', 'smiling', 'and', 'three', 'are', 'wearing', 'a', 'green', 'hat', 'and', 'red', 'brick', 'wall', 'and', 'windows', 'in', 'the', 'background'], ['a', 'large', ',', 'black', 'plastic', 'bag', 'with', 'four', 'packs', 'of', 'pasta', ',', 'a', 'folder', ',', 'a', 'leaflet', ',', 'a', 'small', 'book', 'and', 'cacao', 'powder', 'on', 'a', 'table', 'and', 'there', 'is', 'a', 'second', ',', 'empty', 'table', 'in', 'the', 'background'], ['a', 'yellow', 'building', 'with', 'white', 'columns', 'in', 'the', 'background', 'and', 'two', 'palm', 'trees', 'in', 'front', 'of', 'the', 'house', 'and', 'cars', 'parked', 'in', 'front', 'of', 'the', 'house', 'and', 'a', 'woman', 'and', 'a', 'child', 'are', 'walking', 'over', 'the', 'square'], ['Six', 'pupils', 'are', 'sitting', 'around', 'a', 'round', 'table', 'on', 'wooden', 'chairs', ',', 'each', 'of', 'them', 'is', 'holding', 'a', 'fruit', '(', 'tangerine', '?', ')', 'and', 'is', 'wearing', 'a', 'hat', '(', 'except', 'for', 'one', 'kid', ')', 'and', 'pictures', 'and', 'comics', 'on', 'the', 'wall', 'behind', 'them', 'and', 'car', 'tyres', 'in', 'the', 'background', 'on', 'the', 'right'], ['there', 'are', 'two', 'social', 'workers', 'in', 'the', 'foreground', 'and', 'one', 'wearing', 'a', 'red', 'pullover', 'and', 'brown', 'pants', 'is', 'bending', 'over', 'to', 'access', 'the', 'blue', 'paint', 'and', 'the', 'other', 'one', 'in', 'a', 'red', 'tee-shirt', 'and', 'black', 'jeans', 'is', 'watching', 'her', 'and', 'at', 'the', 'back', 'of', 'the', 'room', 'there', 'is', 'another', 'worker', 'wearing', 'a', 'white', 'tee-shirt', 'and', 'blue', 'jeans', ',', 'acutally', 'painting', 'and', 'there', 'are', 'many', 'newspapers', 'on', 'the', 'ground', 'to', 'protect', 'the', 'kindergarten', 'floor', 'and', 'all', 'three', 'workers', 'are', 'wearing', 'a', 'mask'], ['Six', 'tourists', 'are', 'standing', 'in', 'front', 'of', 'blackboard', 'of', 'a', 'primary', 'school', 'and', 'one', 'tourist', 'is', 'taking', 'a', 'photo', 'and', 'local', 'kids', 'are', 'sitting', 'at', 'their', 'desks', ',', 'singing', 'and', 'clapping', 'and', 'one', 'kid', 'has', 'just', 'opened', 'one', 'book', 'and', 'there', 'are', 'posters', 'and', 'pictures', 'on', 'the', 'wall', 'in', 'the', 'background'], ['View', 'of', 'giant', ',', 'thunderous', 'waterfalls', 'over', 'a', 'u-shaped', 'cliff', 'and', 'white', 'clouds', 'in', 'a', 'blue', 'sky', 'in', 'the', 'background']]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch['captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aics-project",
   "language": "python",
   "name": "aics-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0aa8b618b2a4c99189edcd4356029e9b6dd0644c3169178130b68c1aeecff1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
